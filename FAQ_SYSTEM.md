# Sistema FAQ H√≠brido - Opci√≥n A (Umbrales Dobles 90%/80%)

## üìã Descripci√≥n

Sistema de FAQ con umbrales dobles que combina precisi√≥n y cobertura:
- **Umbral Alto (‚â•90%)**: Match fuerte - Solo FAQs con alta similitud
- **Umbral Medio (80-89%)**: Match medio - FAQs + documentos generales
- **Umbral Bajo (<80%)**: Sin match - Solo documentos generales (flujo original)

## üéØ Ventajas de esta Implementaci√≥n

### ‚úÖ Precisi√≥n M√°xima
- Respuestas exactas para preguntas con match ‚â•90%
- Temperature muy baja (0.1) para FAQs exactos
- Prompts especializados que evitan alucinaciones

### ‚úÖ Cobertura Amplia
- No rechaza preguntas v√°lidas con par√°frasis (80-89%)
- Fallback inteligente a documentos generales
- Sistema h√≠brido en zona gris (combina FAQs + docs)

### ‚úÖ Cero Configuraci√≥n Adicional
- Usa ChromaDB existente (no requiere base de datos separada)
- Embeddings BGE-M3 para similitud sem√°ntica
- Aprovecha infraestructura actual

## üèóÔ∏è Arquitectura del Sistema

```
Usuario ingresa pregunta
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FAQ Handler     ‚îÇ
‚îÇ  Clasifica query ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Similitud?
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì         ‚Üì             ‚Üì          ‚Üì
  ‚â•90%    80-89%          <80%      Comando
  HIGH    MEDIUM           LOW       (skip FAQ)
    ‚Üì         ‚Üì             ‚Üì          ‚Üì
Top-3   Top-2 FAQs     Top-K docs   Flujo
FAQs    + Top-2 docs   (original)    normal
    ‚Üì         ‚Üì             ‚Üì          ‚Üì
Temp=0.1  Temp=0.2      Temp=0.3     -
    ‚Üì         ‚Üì             ‚Üì          ‚Üì
Prompt    Prompt        Prompt       -
FAQ-only  Hybrid        Docs-only    -
    ‚Üì         ‚Üì             ‚Üì          ‚Üì
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚Üì
          LLM (Groq/DeepSeek)
                ‚Üì
            Respuesta
```

## üìÅ Estructura de Archivos

### M√≥dulos Nuevos
```
src/rag/faq_handler.py          # L√≥gica principal de clasificaci√≥n
```

### M√≥dulos Modificados
```
src/rag/rag_pipeline.py         # Agregado query_with_faq()
src/llm/groq_client.py          # Prompts especializados por context_type
src/llm/deepseek_client.py      # Prompts especializados por context_type
src/chatbot/chatbot.py          # Usa query_with_faq() en lugar de query()
src/chat.py                     # Visualizaci√≥n de match types
```

### Documentos FAQ
```
data/docs/faq/
  ‚îú‚îÄ‚îÄ faq_inscripciones.md      # 4 FAQs sobre inscripciones
  ‚îú‚îÄ‚îÄ faq_examenes.md           # 4 FAQs sobre ex√°menes
  ‚îî‚îÄ‚îÄ faq_servicios.md          # 4 FAQs sobre servicios
```

## üîß Componentes Clave

### 1. FAQHandler (`src/rag/faq_handler.py`)

**Responsabilidades:**
- Clasificar queries seg√∫n similitud con FAQs
- Determinar tipo de contexto apropiado
- Ajustar temperature seg√∫n tipo de match

**M√©todos principales:**
```python
classify_query(query, top_k=5) -> dict
    # Retorna: {'match_type': 'high'|'medium'|'low',
    #           'faq_results': [...],
    #           'best_similarity': 0.95}

get_context_for_llm(query, match_type, faq_results, doc_results) -> tuple
    # Retorna: (context_documents, context_type)

get_temperature_for_context(context_type) -> float
    # Retorna: 0.1 (faq_only), 0.2 (faq_and_docs), 0.3 (docs_only)
```

### 2. RAGPipeline - M√©todo Nuevo

**`query_with_faq()`** - Flujo completo:
```python
def query_with_faq(question, top_k=3, temperature=0.7, enable_faq=True):
    """
    1. Clasificar query en FAQs
    2. Obtener documentos seg√∫n match_type
    3. Preparar contexto apropiado
    4. Ajustar temperature
    5. Generar respuesta con LLM
    6. Retornar con metadata (match_type, best_similarity)
    """
```

### 3. Prompts Especializados

**FAQ Only (High Match ‚â•90%):**
```python
system_prompt = """Eres un asistente de FAQ universitario.
REGLAS ESTRICTAS:
1. Responde √öNICAMENTE usando las FAQs proporcionadas
2. Si la pregunta coincide con una FAQ, usa EXACTAMENTE la respuesta
3. NO combines informaci√≥n de m√∫ltiples FAQs a menos que sea necesario
4. NO inventes informaci√≥n ni uses conocimiento externo
5. S√© conciso y directo
"""
```

**FAQ + Docs (Medium Match 80-89%):**
```python
system_prompt = """Eres un asistente universitario.
REGLAS:
1. Tienes FAQs y documentos adicionales
2. PRIORIZA las FAQs si responden la pregunta
3. Usa los documentos solo si las FAQs no son suficientes
4. NO inventes informaci√≥n
"""
```

**Docs Only (Low Match <80%):**
```python
system_prompt = """Eres un asistente √∫til que responde bas√°ndose
√öNICAMENTE en el contexto proporcionado.
Si la informaci√≥n no est√° en el contexto, di claramente que no tienes esa informaci√≥n.
"""
```

## üìä Configuraci√≥n de Umbrales

En `src/rag/faq_handler.py`:
```python
class FAQHandler:
    HIGH_THRESHOLD = 0.90   # Match fuerte: Solo FAQs
    MEDIUM_THRESHOLD = 0.80 # Match medio: FAQs + Docs
```

**¬øC√≥mo ajustar?**
- Aumentar HIGH_THRESHOLD (ej: 0.92) ‚Üí M√°s estricto, menos matches fuertes
- Disminuir HIGH_THRESHOLD (ej: 0.88) ‚Üí M√°s permisivo, m√°s matches fuertes
- Igual para MEDIUM_THRESHOLD

## üöÄ Uso del Sistema

### Opci√≥n 1: Chatbot Interactivo (Recomendado)

```bash
# Activar entorno virtual
source venv/bin/activate

# Ingerir documentos (incluye FAQs)
python src/main.py --ingest

# Iniciar chatbot
python src/chat.py
```

**Salida esperada:**
```
üßë T√∫: ¬øC√≥mo me inscribo a la universidad?

ü§ñ Chatbot: Para inscribirte a la universidad debes...

üéØ Match: FAQ (similitud: 94.2%)

üìö Fuentes consultadas:
  1. ‚ùì faq_inscripciones.md (similitud: 94.2%)
  2. ‚ùì faq_inscripciones.md (similitud: 87.3%)
```

### Opci√≥n 2: Consultas Directas

```bash
python src/main.py --query "¬øCu√°ndo son los ex√°menes finales?"
```

### Opci√≥n 3: Desde C√≥digo

```python
from rag.rag_pipeline import RAGPipeline

# Inicializar pipeline
pipeline = RAGPipeline(llm_provider="groq")

# Consulta con FAQ
result = pipeline.query_with_faq(
    question="¬øC√≥mo me inscribo?",
    top_k=3,
    enable_faq=True
)

print(f"Respuesta: {result['answer']}")
print(f"Match type: {result['match_type']}")  # 'high', 'medium', 'low'
print(f"Best FAQ similarity: {result['best_faq_similarity']:.2%}")
```

## üìù Formato de FAQs

Los FAQs deben seguir este formato en archivos markdown:

```markdown
# FAQ - T√≠tulo del Tema

## Pregunta 1: T√≠tulo descriptivo

**Pregunta:** ¬øPregunta principal? / ¬øVariante 1? / ¬øVariante 2?

**Respuesta:** Respuesta clara y concisa a la pregunta.
Puede tener m√∫ltiples p√°rrafos si es necesario.

---

## Pregunta 2: Otro t√≠tulo

**Pregunta:** ¬øOtra pregunta?

**Respuesta:** Otra respuesta...
```

**Buenas pr√°cticas:**
- Incluir variantes de la pregunta despu√©s de `/`
- Respuestas concisas pero completas
- Un tema por archivo (ej: `faq_inscripciones.md`)
- Separar preguntas con `---`

## üß™ Casos de Prueba

### High Match (‚â•90% - Solo FAQs)

```python
test_queries_high = [
    "¬øC√≥mo me inscribo a la universidad?",
    "¬øCu√°ndo abren las inscripciones?",
    "¬øQu√© documentos necesito para inscribirme?",
    "¬øCu√°nto cuesta la matr√≠cula?",
    "¬øCu√°ndo son los ex√°menes finales?",
]
```

**Resultado esperado:**
- Match type: `high`
- Temperature: `0.1`
- Contexto: Top-3 FAQs solamente
- Similitud: ‚â•90%

### Medium Match (80-89% - FAQs + Docs)

```python
test_queries_medium = [
    "¬øCu√°l es el proceso de inscripci√≥n?",  # Par√°frasis de "¬øC√≥mo me inscribo?"
    "¬øEn qu√© fecha inician las inscripciones?",  # Par√°frasis
    "¬øCu√°les son los requisitos?",  # M√°s general
]
```

**Resultado esperado:**
- Match type: `medium`
- Temperature: `0.2`
- Contexto: Top-2 FAQs + Top-2 docs generales
- Similitud: 80-89%

### Low Match (<80% - Solo Docs)

```python
test_queries_low = [
    "¬øQu√© informaci√≥n tienes sobre becas?",
    "H√°blame de las menciones honor√≠ficas",
    "¬øQu√© programas acad√©micos ofrecen?",
]
```

**Resultado esperado:**
- Match type: `low`
- Temperature: `0.3`
- Contexto: Solo documentos generales (flujo original)
- Similitud: <80%

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Ajustar n√∫mero de FAQs/Docs por match type

En `src/rag/faq_handler.py`, m√©todo `get_context_for_llm()`:

```python
# HIGH MATCH - Cambiar de top-3 a top-5 FAQs
context = [content for _, content, _ in faq_results[:5]]  # Era [:3]

# MEDIUM MATCH - Cambiar balance FAQs/Docs
faq_context = [content for _, content, _ in faq_results[:3]]  # Era [:2]
doc_context = [content for _, content, _ in doc_results[:1]]  # Era [:2]
```

### Cambiar temperatures

En `src/rag/faq_handler.py`, m√©todo `get_temperature_for_context()`:

```python
temperatures = {
    'faq_only': 0.05,      # M√°s determinista (era 0.1)
    'faq_and_docs': 0.3,   # M√°s creativo (era 0.2)
    'docs_only': 0.4       # M√°s flexible (era 0.3)
}
```

### Deshabilitar FAQs temporalmente

```python
result = pipeline.query_with_faq(
    question="Tu pregunta",
    enable_faq=False  # Fuerza uso de documentos generales
)
```

## üêõ Troubleshooting

### Problema: Todas las queries son LOW match

**Causa:** Los FAQs no fueron ingeridos correctamente.

**Soluci√≥n:**
```bash
# Verificar que los FAQs existen
ls data/docs/faq/

# Re-ingerir forzando actualizaci√≥n
python src/main.py --ingest --force
```

### Problema: Similitudes son muy bajas (<70%)

**Causa:** Modelo BGE-M3 no descargado o preguntas muy diferentes.

**Soluci√≥n:**
- Verifica que BGE-M3 est√© en `~/.cache/huggingface/`
- Revisa el formato de tus FAQs
- Agrega m√°s variantes de preguntas en los FAQs

### Problema: Respuestas inventan informaci√≥n

**Causa:** Temperature muy alta o prompts no suficientemente estrictos.

**Soluci√≥n:**
- Reduce temperature en `faq_handler.py`
- Verifica que `context_type` se pase correctamente al LLM
- Revisa los prompts en `groq_client.py` o `deepseek_client.py`

## üìà M√©tricas y Monitoreo

El sistema retorna metadata √∫til para monitoreo:

```python
result = pipeline.query_with_faq(question)

# M√©tricas disponibles
match_type = result['match_type']  # 'high', 'medium', 'low'
best_similarity = result['best_faq_similarity']  # 0.0-1.0
context_type = result['context_type']  # 'faq_only', 'faq_and_docs', 'docs_only'
relevant_docs = result['relevant_documents']  # Lista con fuentes
```

**Ejemplo de logging:**
```python
print(f"Query: {question}")
print(f"Match: {match_type} ({best_similarity:.1%})")
print(f"Context: {context_type}")
print(f"Sources: {len(relevant_docs)}")
```

## üîÑ Actualizar FAQs

### Agregar nuevos FAQs

1. Crear archivo en `data/docs/faq/faq_nuevo_tema.md`
2. Seguir formato est√°ndar (ver secci√≥n "Formato de FAQs")
3. Re-ingerir documentos:
   ```bash
   python src/main.py --ingest
   ```

### Modificar FAQs existentes

1. Editar archivo correspondiente
2. Re-ingerir forzando actualizaci√≥n:
   ```bash
   python src/main.py --ingest --force
   ```

### Eliminar FAQs

1. Borrar archivo de FAQ
2. Limpiar base de datos y re-ingerir:
   ```bash
   python src/main.py --reset
   python src/main.py --ingest
   ```

## üí° Mejoras Futuras Sugeridas

### 1. Cache de FAQs frecuentes
```python
# Guardar en memoria los FAQs m√°s consultados
faq_cache = {}  # {query_hash: (answer, similarity)}
```

### 2. Feedback de usuarios
```python
# Agregar sistema de "¬øTe fue √∫til esta respuesta?"
result['useful'] = user_feedback()  # True/False
# Log para analizar qu√© FAQs necesitan mejora
```

### 3. Re-ranking con cross-encoder
```python
# Despu√©s de BGE-M3, re-rankear con modelo m√°s preciso
from sentence_transformers import CrossEncoder
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
scores = reranker.predict([(query, faq) for faq in faq_results])
```

### 4. Detecci√≥n de preguntas fuera de alcance
```python
# Si best_similarity < 60%, sugerir contactar soporte
if best_similarity < 0.60:
    return "Esta pregunta est√° fuera de mi alcance. Por favor contacta a..."
```

## üìû Soporte

Si encuentras problemas o tienes sugerencias:

1. Revisa la secci√≥n Troubleshooting
2. Verifica los logs en consola
3. Prueba con `enable_faq=False` para verificar si es problema de FAQs
4. Revisa que ChromaDB tenga documentos: `python src/main.py --stats`

## üéì Conclusi√≥n

Este sistema FAQ h√≠brido con umbrales dobles (90%/80%) ofrece el **mejor balance entre precisi√≥n y cobertura**:

- ‚úÖ **Alta precisi√≥n** en matches fuertes (‚â•90%)
- ‚úÖ **Cobertura amplia** con zona media (80-89%)
- ‚úÖ **Fallback robusto** a documentos generales (<80%)
- ‚úÖ **Cero alucinaciones** con prompts estrictos
- ‚úÖ **F√°cil mantenimiento** de FAQs (archivos markdown)

**¬°Tu sistema est√° listo para producci√≥n!** üöÄ
